{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1816e696",
   "metadata": {},
   "source": [
    "## VAE-MS\n",
    "This is a Minimal Working Example of the VAE-MS. Firstly the nessecary modules are loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e7f37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from VAEMS_init import *\n",
    "from train_loop import train\n",
    "from utils import initialize_nmf, poisnll\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c8506",
   "metadata": {},
   "source": [
    "For this tutorial we are using randomly generated integer data with 1000 observations with 96 'mutation types'. This data is 100x normalized, used to generate NMF-based priors and divided into train/validation/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f0c9bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bjyw\\AppData\\Local\\Temp\\ipykernel_12052\\2954932638.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(catalogue[train_val_idx, :], dtype=torch.float32),\n",
      "C:\\Users\\bjyw\\AppData\\Local\\Temp\\ipykernel_12052\\2954932638.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(catalogue[test_idx, :], dtype=torch.float32),\n"
     ]
    }
   ],
   "source": [
    "catalogue = torch.randint(low = 0, high = 180, size = (1000, 96))\n",
    "n_pat, n_mut = catalogue.shape\n",
    "\n",
    "h_dim = 3\n",
    "\n",
    "catalogue_norm = np.array(catalogue[:])\n",
    "totalMutations = catalogue.sum(axis=1)\n",
    "indices = np.where(totalMutations > (n_mut * 100))\n",
    "norm_genome = (\n",
    "        np.array(catalogue)[indices[0],:]\n",
    "        / np.array(totalMutations)[indices[0]][:,np.newaxis]\n",
    "        * (n_mut * 100)\n",
    "    )\n",
    "catalogue_norm[list(indices),:] = norm_genome\n",
    "catalogue_norm = pd.DataFrame(catalogue_norm)\n",
    "\n",
    "train_val_idx, test_idx = train_test_split(range(n_pat), test_size=0.2)\n",
    "train_idx, validation_idx = train_test_split(train_val_idx, test_size=0.2)\n",
    "\n",
    "lamdba_prior_train, lamdba_prior_val, lamdba_prior_test, start_sigs, start_error = initialize_nmf(\n",
    "        catalogue_norm, train_idx, validation_idx, test_idx, h_dim=h_dim, tol=1e-10)\n",
    "\n",
    "\n",
    "################## Trainloader ###################################################\n",
    "\n",
    "# Normalized data for training\n",
    "train_data_norm = TensorDataset(\n",
    "        torch.tensor(catalogue_norm.values[train_idx, :], dtype=torch.float32),\n",
    "        torch.tensor(lamdba_prior_train.values, dtype=torch.float32))\n",
    "validation_data_norm = TensorDataset(\n",
    "        torch.tensor(catalogue_norm.values[validation_idx, :], dtype=torch.float32),\n",
    "        torch.tensor(lamdba_prior_val.values, dtype=torch.float32))\n",
    "\n",
    "# Unnormalized data for evaluation\n",
    "trainval_prior = pd.concat([lamdba_prior_train,lamdba_prior_val]).values\n",
    "trainval_data = TensorDataset(\n",
    "        torch.tensor(catalogue[train_val_idx, :], dtype=torch.float32),\n",
    "        torch.tensor(trainval_prior, dtype=torch.float32))\n",
    "test_data = TensorDataset(\n",
    "        torch.tensor(catalogue[test_idx, :], dtype=torch.float32),\n",
    "        torch.tensor(lamdba_prior_test.values, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a9d32",
   "metadata": {},
   "source": [
    "Next, we configure the VAE-MS model with hyperparameters stored in the 'config' dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51cde5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "config = dict(\n",
    "        l_dim = [60, 40],\n",
    "        batch_size = 16,\n",
    "        learning_rate = 1e-3,\n",
    "        activation = \"ReLU\",\n",
    "        beta_kl =0.01,\n",
    "        optimizer = \"Adam\",\n",
    "        h_dim = h_dim)\n",
    "\n",
    "model = VAEMS(\n",
    "            input_dim=n_mut,\n",
    "            l_dim=config['l_dim'],\n",
    "            h_dim=config['h_dim'],\n",
    "            activation=config['activation'],\n",
    "            start_sigs= start_sigs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b40bb2e",
   "metadata": {},
   "source": [
    "Now training is performed for 500 epochs with early stopping using the 'Adam' optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7fa3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 701.4787, Val Loss: 116.8415\n",
      "best val loss 116.8415 updated at 1 epochs after 0 epochs without improvement\n",
      "Epoch [2/500], Train Loss: 575.0501, Val Loss: 116.3988\n",
      "best val loss 116.3988 updated at 2 epochs after 0 epochs without improvement\n",
      "Epoch [3/500], Train Loss: 522.3417, Val Loss: 115.7296\n",
      "best val loss 115.7296 updated at 3 epochs after 0 epochs without improvement\n",
      "Epoch [4/500], Train Loss: 487.0071, Val Loss: 115.5176\n",
      "best val loss 115.5176 updated at 4 epochs after 0 epochs without improvement\n",
      "Epoch [5/500], Train Loss: 458.3468, Val Loss: 114.8387\n",
      "best val loss 114.8387 updated at 5 epochs after 0 epochs without improvement\n",
      "Epoch [6/500], Train Loss: 432.4667, Val Loss: 114.3674\n",
      "best val loss 114.3674 updated at 6 epochs after 0 epochs without improvement\n",
      "Epoch [7/500], Train Loss: 409.9308, Val Loss: 113.0938\n",
      "best val loss 113.0938 updated at 7 epochs after 0 epochs without improvement\n",
      "Epoch [8/500], Train Loss: 388.9146, Val Loss: 112.5538\n",
      "best val loss 112.5538 updated at 8 epochs after 0 epochs without improvement\n",
      "Epoch [9/500], Train Loss: 369.3732, Val Loss: 110.8304\n",
      "best val loss 110.8304 updated at 9 epochs after 0 epochs without improvement\n",
      "Epoch [10/500], Train Loss: 350.6243, Val Loss: 108.4217\n",
      "best val loss 108.4217 updated at 10 epochs after 0 epochs without improvement\n",
      "Epoch [11/500], Train Loss: 330.7702, Val Loss: 108.6039\n",
      "Epoch [12/500], Train Loss: 312.3255, Val Loss: 105.9588\n",
      "best val loss 105.9588 updated at 12 epochs after 1 epochs without improvement\n",
      "Epoch [13/500], Train Loss: 295.0948, Val Loss: 104.9655\n",
      "best val loss 104.9655 updated at 13 epochs after 0 epochs without improvement\n",
      "Epoch [14/500], Train Loss: 279.4425, Val Loss: 104.1587\n",
      "best val loss 104.1587 updated at 14 epochs after 0 epochs without improvement\n",
      "Epoch [15/500], Train Loss: 262.6959, Val Loss: 101.0172\n",
      "best val loss 101.0172 updated at 15 epochs after 0 epochs without improvement\n",
      "Epoch [16/500], Train Loss: 249.4719, Val Loss: 98.3250\n",
      "best val loss 98.3250 updated at 16 epochs after 0 epochs without improvement\n",
      "Epoch [17/500], Train Loss: 235.1103, Val Loss: 96.0914\n",
      "best val loss 96.0914 updated at 17 epochs after 0 epochs without improvement\n",
      "Epoch [18/500], Train Loss: 218.7960, Val Loss: 93.6322\n",
      "best val loss 93.6322 updated at 18 epochs after 0 epochs without improvement\n",
      "Epoch [19/500], Train Loss: 203.0023, Val Loss: 91.5381\n",
      "best val loss 91.5381 updated at 19 epochs after 0 epochs without improvement\n",
      "Epoch [20/500], Train Loss: 190.8538, Val Loss: 88.3209\n",
      "best val loss 88.3209 updated at 20 epochs after 0 epochs without improvement\n",
      "Epoch [21/500], Train Loss: 180.5802, Val Loss: 85.5615\n",
      "best val loss 85.5615 updated at 21 epochs after 0 epochs without improvement\n",
      "Epoch [22/500], Train Loss: 169.5567, Val Loss: 84.2067\n",
      "best val loss 84.2067 updated at 22 epochs after 0 epochs without improvement\n",
      "Epoch [23/500], Train Loss: 161.2100, Val Loss: 79.9911\n",
      "best val loss 79.9911 updated at 23 epochs after 0 epochs without improvement\n",
      "Epoch [24/500], Train Loss: 152.7220, Val Loss: 78.4526\n",
      "best val loss 78.4526 updated at 24 epochs after 0 epochs without improvement\n",
      "Epoch [25/500], Train Loss: 144.4173, Val Loss: 74.8659\n",
      "best val loss 74.8659 updated at 25 epochs after 0 epochs without improvement\n",
      "Epoch [26/500], Train Loss: 136.6412, Val Loss: 72.9453\n",
      "best val loss 72.9453 updated at 26 epochs after 0 epochs without improvement\n",
      "Epoch [27/500], Train Loss: 129.4996, Val Loss: 71.4098\n",
      "best val loss 71.4098 updated at 27 epochs after 0 epochs without improvement\n",
      "Epoch [28/500], Train Loss: 122.1598, Val Loss: 68.0593\n",
      "best val loss 68.0593 updated at 28 epochs after 0 epochs without improvement\n",
      "Epoch [29/500], Train Loss: 116.1627, Val Loss: 68.0788\n",
      "Epoch [30/500], Train Loss: 110.0109, Val Loss: 63.0444\n",
      "best val loss 63.0444 updated at 30 epochs after 1 epochs without improvement\n",
      "Epoch [31/500], Train Loss: 103.8085, Val Loss: 61.9933\n",
      "best val loss 61.9933 updated at 31 epochs after 0 epochs without improvement\n",
      "Epoch [32/500], Train Loss: 98.5477, Val Loss: 59.0037\n",
      "best val loss 59.0037 updated at 32 epochs after 0 epochs without improvement\n",
      "Epoch [33/500], Train Loss: 92.5586, Val Loss: 56.9680\n",
      "best val loss 56.9680 updated at 33 epochs after 0 epochs without improvement\n",
      "Epoch [34/500], Train Loss: 88.2739, Val Loss: 56.1553\n",
      "best val loss 56.1553 updated at 34 epochs after 0 epochs without improvement\n",
      "Epoch [35/500], Train Loss: 84.2648, Val Loss: 53.3246\n",
      "best val loss 53.3246 updated at 35 epochs after 0 epochs without improvement\n",
      "Epoch [36/500], Train Loss: 80.2842, Val Loss: 51.9601\n",
      "best val loss 51.9601 updated at 36 epochs after 0 epochs without improvement\n",
      "Epoch [37/500], Train Loss: 75.8878, Val Loss: 51.7902\n",
      "best val loss 51.7902 updated at 37 epochs after 0 epochs without improvement\n",
      "Epoch [38/500], Train Loss: 72.3864, Val Loss: 49.9613\n",
      "best val loss 49.9613 updated at 38 epochs after 0 epochs without improvement\n",
      "Epoch [39/500], Train Loss: 68.7810, Val Loss: 47.3862\n",
      "best val loss 47.3862 updated at 39 epochs after 0 epochs without improvement\n",
      "Epoch [40/500], Train Loss: 65.3224, Val Loss: 46.5278\n",
      "best val loss 46.5278 updated at 40 epochs after 0 epochs without improvement\n",
      "Epoch [41/500], Train Loss: 63.2210, Val Loss: 44.6160\n",
      "best val loss 44.6160 updated at 41 epochs after 0 epochs without improvement\n",
      "Epoch [42/500], Train Loss: 59.3996, Val Loss: 44.1768\n",
      "best val loss 44.1768 updated at 42 epochs after 0 epochs without improvement\n",
      "Epoch [43/500], Train Loss: 56.9777, Val Loss: 43.1891\n",
      "best val loss 43.1891 updated at 43 epochs after 0 epochs without improvement\n",
      "Epoch [44/500], Train Loss: 54.9001, Val Loss: 42.6489\n",
      "best val loss 42.6489 updated at 44 epochs after 0 epochs without improvement\n",
      "Epoch [45/500], Train Loss: 52.4884, Val Loss: 42.4251\n",
      "best val loss 42.4251 updated at 45 epochs after 0 epochs without improvement\n",
      "Epoch [46/500], Train Loss: 50.1954, Val Loss: 40.3036\n",
      "best val loss 40.3036 updated at 46 epochs after 0 epochs without improvement\n",
      "Epoch [47/500], Train Loss: 47.6915, Val Loss: 40.1227\n",
      "best val loss 40.1227 updated at 47 epochs after 0 epochs without improvement\n",
      "Epoch [48/500], Train Loss: 46.1604, Val Loss: 39.0145\n",
      "best val loss 39.0145 updated at 48 epochs after 0 epochs without improvement\n",
      "Epoch [49/500], Train Loss: 44.6312, Val Loss: 38.7475\n",
      "best val loss 38.7475 updated at 49 epochs after 0 epochs without improvement\n",
      "Epoch [50/500], Train Loss: 42.8958, Val Loss: 38.9787\n",
      "Epoch [51/500], Train Loss: 41.7916, Val Loss: 37.9400\n",
      "best val loss 37.9400 updated at 51 epochs after 1 epochs without improvement\n",
      "Epoch [52/500], Train Loss: 40.5267, Val Loss: 37.9054\n",
      "best val loss 37.9054 updated at 52 epochs after 0 epochs without improvement\n",
      "Epoch [53/500], Train Loss: 39.4010, Val Loss: 37.5946\n",
      "best val loss 37.5946 updated at 53 epochs after 0 epochs without improvement\n",
      "Epoch [54/500], Train Loss: 37.8869, Val Loss: 37.9701\n",
      "Epoch [55/500], Train Loss: 37.7889, Val Loss: 38.6988\n",
      "Epoch [56/500], Train Loss: 36.2938, Val Loss: 36.7419\n",
      "best val loss 36.7419 updated at 56 epochs after 2 epochs without improvement\n",
      "Epoch [57/500], Train Loss: 35.5727, Val Loss: 37.2601\n",
      "Epoch [58/500], Train Loss: 35.4647, Val Loss: 37.1492\n",
      "Epoch [59/500], Train Loss: 33.9790, Val Loss: 36.9518\n",
      "Epoch [60/500], Train Loss: 33.9280, Val Loss: 36.9548\n",
      "Epoch [61/500], Train Loss: 33.0235, Val Loss: 36.6683\n",
      "best val loss 36.6683 updated at 61 epochs after 4 epochs without improvement\n",
      "Epoch [62/500], Train Loss: 31.9661, Val Loss: 37.0036\n",
      "Epoch [63/500], Train Loss: 32.1378, Val Loss: 36.9761\n",
      "Epoch [64/500], Train Loss: 31.2769, Val Loss: 37.0708\n",
      "Epoch [65/500], Train Loss: 31.3727, Val Loss: 37.1130\n",
      "Epoch [66/500], Train Loss: 30.9128, Val Loss: 36.9600\n",
      "Epoch [67/500], Train Loss: 30.4370, Val Loss: 37.2951\n",
      "Epoch [68/500], Train Loss: 30.1016, Val Loss: 37.5006\n",
      "Epoch [69/500], Train Loss: 30.2089, Val Loss: 37.8285\n",
      "Epoch [70/500], Train Loss: 30.3703, Val Loss: 37.1639\n",
      "Epoch [71/500], Train Loss: 29.4393, Val Loss: 37.9365\n",
      "Early stopping triggered after 71 epochs with best val loss 36.6683\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_data_norm, batch_size=config['batch_size'], shuffle=True)\n",
    "val_dl = DataLoader(validation_data_norm, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "optimizer = getattr(torch.optim, config['optimizer'])(model.parameters(), lr=config['learning_rate'])\n",
    "\n",
    "best_model, _, best_val_loss, _, _ = train(\n",
    "    device=device,\n",
    "    num_epochs=500,\n",
    "    model=model,\n",
    "    input_dim=n_mut,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn= poisnll,\n",
    "    trainloader=train_dl,\n",
    "    valloader=val_dl,\n",
    "    beta_kl=config['beta_kl'],\n",
    "     patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc9f4c3",
   "metadata": {},
   "source": [
    "Lastly, post training, variables are extracted and metrics are calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a5e8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ EVALUATION LOGIC ##############################################\n",
    "best_model.eval()\n",
    "\n",
    "############################################ EXTRACT PARAMS ###############################################\n",
    "                \n",
    "vhat, _, Poisson_dist, signatures_est = best_model(trainval_data.tensors) \n",
    "exp_train = pd.DataFrame(Poisson_dist.rate.detach().numpy())\n",
    "vhat_te, _, Poisson_dist_te,_ = best_model(test_data.tensors)\n",
    "exp_test = pd.DataFrame(Poisson_dist_te.rate.detach().numpy())\n",
    "\n",
    "signatures_est = pd.DataFrame(signatures_est.data.detach().numpy().T)\n",
    "\n",
    "\n",
    "#################################### EVAULATE LOSS #############################################\n",
    "reconst_loss = poisnll(trainval_data.tensors[0], vhat)\n",
    "kl_div = Poisson_dist.kl(trainval_data.tensors[1])\n",
    "loss_train = reconst_loss + config['beta_kl'] * kl_div.mean()\n",
    "\n",
    "reconst_loss_te = poisnll(test_data.tensors[0], vhat_te)\n",
    "kl_div_te = Poisson_dist_te.kl(test_data.tensors[1]).mean()\n",
    "loss_test = reconst_loss_te + config['beta_kl'] * kl_div_te\n",
    "\n",
    "#################################### COMPUTE METRICS ####################################################\n",
    "mse_est = np.mean(pd.DataFrame(((catalogue[train_val_idx,:] - vhat) ** 2).detach().numpy()))\n",
    "mse_test = np.mean(pd.DataFrame(((catalogue[test_idx,:] - vhat_te) ** 2).detach().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
